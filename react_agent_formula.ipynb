{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22192a46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61f24865",
   "metadata": {},
   "source": [
    "Import all our necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b48bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import inspect\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from typing import (TypedDict, List, Dict, Literal, Callable, Optional, Any, get_type_hints)\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "from openai.types.chat.chat_completion_message_tool_call import ChatCompletionMessageToolCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7835b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86efa98",
   "metadata": {},
   "source": [
    "Insert our Memory class object. We built this class in order to have a standardized memory function object that will behave across all our AI use cases. This use case being a ReAct agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88b1089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self._messages: List[Dict[str, str]] = []\n",
    "\n",
    "    def add_message(self, \n",
    "        role: Literal['user', 'system', 'assistant', 'tool'], \n",
    "        content: str,\n",
    "        tool_calls: dict=dict(),\n",
    "        tool_call_id=None)->None:\n",
    "\n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"tool_calls\": tool_calls,\n",
    "        }\n",
    "\n",
    "        if role == \"tool\":\n",
    "            message = {\n",
    "                \"role\": role,\n",
    "                \"content\": content,\n",
    "                \"tool_call_id\": tool_call_id,\n",
    "            }\n",
    "\n",
    "        self._messages.append(message)\n",
    "    \n",
    "    def get_messages(self) -> List[Dict[str, str]]:\n",
    "        return self._messages\n",
    "    \n",
    "    def last_message(self) -> None:\n",
    "        if self._messages:\n",
    "            return self._messages[-1]\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._messages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a0c0a",
   "metadata": {},
   "source": [
    "Insert our Tool class object. Similar to how we created our memory class, we created a Tool class object so that we could leverage the framework and its behavior repeatedly in multiple different use cases. This use case being a ReAct Agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35d260",
   "metadata": {},
   "source": [
    "class below has been updated and is the best version of this object i have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96498147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool:\n",
    "    def __init__(self, func:Callable):\n",
    "        self.func = func\n",
    "        self.name = func.__name__\n",
    "        self.description = func.__doc__\n",
    "        self.argument_types_map = get_type_hints(func)\n",
    "        self.signature = inspect.signature(func)\n",
    "        self.arguments = [\n",
    "            {\n",
    "                \"name\": key,\n",
    "                \"type\":self._infer_json_schema_type(value),\n",
    "                \"required\": param.default == inspect.Parameter.empty\n",
    "            }\n",
    "            for key, value in self.argument_types_map.items()\n",
    "            if (param := self.signature.parameters.get(key))\n",
    "        ]\n",
    "\n",
    "    def dict(self):\n",
    "        return{\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": self.description,\n",
    "                \"parallel_tool_calls\": False,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        argument[\"name\"]: {\n",
    "                            \"type\": argument[\"type\"],\n",
    "                        }\n",
    "                        for argument in self.arguments\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        argument[\"name\"]\n",
    "                        for argument in self.arguments\n",
    "                        if argument[\"required\"]\n",
    "                    ],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def __call__ (self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "\n",
    "    def _infer_json_schema_type(self, arg_type: Any) -> str:\n",
    "        if arg_type == bool:\n",
    "            return \"boolean\"\n",
    "        elif arg_type == int:\n",
    "            return \"integer\"\n",
    "        elif arg_type == float:\n",
    "            return \"number\"\n",
    "        elif arg_type == str:\n",
    "            return \"string\"\n",
    "        elif arg_type == list:\n",
    "            return \"array\"\n",
    "        elif arg_type == dict:\n",
    "            return \"object\"\n",
    "        elif arg_type == None:\n",
    "            return \"Null\"\n",
    "        elif arg_type == datetime.date or arg_type == datetime.datetime:\n",
    "            return \"string\"\n",
    "        else:\n",
    "            return \"string\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ba0679",
   "metadata": {},
   "source": [
    "In this use case, we will build a ReAct Tool loop. in order to create a usable loop, we need the loop to stop at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416f31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopReactLoopException(Exception):\n",
    "    \"\"\"\n",
    "    Terminates React Loop.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e96fabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMINATION_MESSAGE = \"StopReactLoopException\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ccb0e",
   "metadata": {},
   "source": [
    "Next, we need a function that we'll be using as a tool so the LLM knows when to terminate the loop. once we have that function, we can continue to work on our agent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7459863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def termination()-> str:\n",
    "    \"\"\"Terminate the ReAct Loop. If the agent thinks theres no further action to take\"\"\"\n",
    "    return TERMINATION_MESSAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0fd32",
   "metadata": {},
   "source": [
    "Now lets build our Agent Class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e0760a",
   "metadata": {},
   "source": [
    "The first def __init__ is the python class constructor. This function is the special method that gets called when we create a new object from a class. It's main job is to initialize the new object's state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff02be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"A ReAct AI Agent\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name:str = \"Agent\",\n",
    "        role:str = \"Personal Assistant\",\n",
    "        instructions:str = \"Help users with any questions\",\n",
    "        model:str = \"gpt-4o-mini\",\n",
    "        temperature:float = 0.1,\n",
    "        tools:List[Tool] = [],\n",
    "        ):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.client = OpenAI()\n",
    "        self.tools = tools\n",
    "        self.termination_message = TERMINATION_MESSAGE\n",
    "        self._register_tool(Tool(termination))\n",
    "        self.tool_map = {t.name:t for t in tools}\n",
    "        self.openai_tools = [t.dict() for t in self.tools] if self.tools else None\n",
    "        self.memory = Memory()\n",
    "\n",
    "        self.memory.add_message(\n",
    "            role=\"system\",\n",
    "            content=f\"You're an AI agent, your role is {self.role}, \"\n",
    "                    f\"and you need to {self.instructions} \"\n",
    "                    \"You can answer multistep questions by sequentially calling functions. \"\n",
    "                    \"You follow a pattern of thought and action. \"\n",
    "                    \"Create a plan of execution: \"\n",
    "                    \"- Use thought to describe your thoughts about the question you've been asked. \"\n",
    "                    \"- Use action to specify one of the tools available to you. \"\n",
    "                    \"When you think its over, call the termination tool. \"\n",
    "                    \"Never try to respond directly if the question requires a tool.\"\n",
    "                    \"The actions you have are the tools: \"\n",
    "                    f\"{self.openai_tools}\",\n",
    "        )\n",
    "\n",
    "    def invoke(self, user_message: str, max_iter:int=3) -> str:\n",
    "        self.memory.add_message(\n",
    "            role=\"user\",\n",
    "            content=user_message,\n",
    "        )\n",
    "        try:\n",
    "            self._react_loop(max_iter)\n",
    "        except StopReactLoopException as e:\n",
    "            print(f\"Terminated loop with message: '{e}'\")\n",
    "            self._reason()\n",
    "\n",
    "        return self.memory.last_message()\n",
    "    \n",
    "    def _react_loop(self, max_iter:int):\n",
    "        for i in range(max_iter):\n",
    "            self._reason()\n",
    "\n",
    "            ai_message = self._get_completion(\n",
    "                messages = self.memory.get_messages(),\n",
    "                tools=self.openai_tools,\n",
    "            )\n",
    "            tool_calls = ai_message.tool_calls\n",
    "\n",
    "            self.memory.add_message(\n",
    "                role=\"assistant\",\n",
    "                content=ai_message.content,\n",
    "                tool_calls=tool_calls,\n",
    "            )\n",
    "\n",
    "            if tool_calls:\n",
    "                self._call_tools(tool_calls)\n",
    "            \n",
    "    def _reason(self):\n",
    "        ai_message = self._get_completion(\n",
    "            messages = self.memory.get_messages(),\n",
    "        )\n",
    "\n",
    "        self.memory.add_message(\n",
    "            role=\"assistant\",\n",
    "            content=ai_message.content,\n",
    "            tool_calls=None,\n",
    "        )\n",
    "\n",
    "    def _call_tools(self, tool_calls:List[ChatCompletionMessageToolCall]):\n",
    "        for t in tool_calls:\n",
    "            tool_call_id = t.id\n",
    "            function_name = t.function.name\n",
    "            args = json.loads(t.function.arguments)\n",
    "            callable_tool = self.tool_map[function_name]\n",
    "            result = callable_tool(**args)\n",
    "            self.memory.add_message(\n",
    "                role=\"tool\",\n",
    "                content=str(result),\n",
    "                tool_call_id=tool_call_id,\n",
    "            )\n",
    "            if result == TERMINATION_MESSAGE:\n",
    "                raise StopReactLoopException(TERMINATION_MESSAGE)\n",
    "    \n",
    "    def _get_completion(self, messages:List[Dict], tools:List=None)-> ChatCompletionMessage:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            temperature=self.temperature,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message\n",
    "    \n",
    "    def _register_tool(self, tool:Tool):\n",
    "        self.tools.append(tool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2de95106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(base:float, exponent:float):\n",
    "    \"\"\"Exponentiation: base to the power of exponent.\"\"\"\n",
    "\n",
    "    return base ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e2a4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum(num_1:float, num_2:float):\n",
    "    \"\"\"Sum/Addition: Add two numbers.\"\"\"\n",
    "    \n",
    "    return num_1 + num_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5161d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [power, sum]\n",
    "tools = [Tool(func) for func in funcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74de46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c3882c",
   "metadata": {},
   "source": [
    "we have our agent and now we can invoke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45d6f61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated loop with message: 'StopReactLoopException'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'The calculation is complete. If you have any more questions or need further assistance, feel free to ask!',\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"what is 2 to the power of 3? then add 11 to the result.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1244449b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You're an AI agent, your role is Personal Assistant, and you need to Help users with any questions You can answer multistep questions by sequentially calling functions. You follow a pattern of thought and action. Create a plan of execution: - Use thought to describe your thoughts about the question you've been asked. - Use action to specify one of the tools available to you. When you think its over, call the termination tool. Never try to respond directly if the question requires a tool.The actions you have are the tools: [{'type': 'function', 'function': {'name': 'power', 'description': 'Exponentiation: base to the power of exponent.', 'parallel_tool_calls': False, 'parameters': {'type': 'object', 'properties': {'base': {'type': 'number'}, 'exponent': {'type': 'number'}}, 'required': ['base', 'exponent'], 'additionalProperties': False}, 'strict': True}}, {'type': 'function', 'function': {'name': 'sum', 'description': 'Sum/Addition: Add two numbers.', 'parallel_tool_calls': False, 'parameters': {'type': 'object', 'properties': {'num_1': {'type': 'number'}, 'num_2': {'type': 'number'}}, 'required': ['num_1', 'num_2'], 'additionalProperties': False}, 'strict': True}}, {'type': 'function', 'function': {'name': 'termination', 'description': 'Terminate the ReAct Loop. If the agent thinks theres no further action to take', 'parallel_tool_calls': False, 'parameters': {'type': 'object', 'properties': {}, 'required': [], 'additionalProperties': False}, 'strict': True}}]\",\n",
       "  'tool_calls': {}},\n",
       " {'role': 'user',\n",
       "  'content': 'what is 2 to the power of 3? then add 11 to the result.',\n",
       "  'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': \"To solve the question, I need to first calculate \\\\(2\\\\) to the power of \\\\(3\\\\), and then I will add \\\\(11\\\\) to that result.\\n\\n1. Calculate \\\\(2^3\\\\).\\n2. Add \\\\(11\\\\) to the result of \\\\(2^3\\\\).\\n\\nLet's start with the first step by calculating \\\\(2^3\\\\). I'll proceed with that now.\",\n",
       "  'tool_calls': None},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_HtCRO1ftHwTGlX4Mp4kNtcbl', function=Function(arguments='{\"base\":2,\"exponent\":3}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '8',\n",
       "  'tool_call_id': 'call_HtCRO1ftHwTGlX4Mp4kNtcbl'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"The result of \\\\(2^3\\\\) is \\\\(8\\\\). Now, I will add \\\\(11\\\\) to this result. \\n\\nLet's proceed with that calculation.\",\n",
       "  'tool_calls': None},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_QCchvKp6V6q3biMbngK0D2b9', function=Function(arguments='{\"num_1\":8,\"num_2\":11}', name='sum'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '19',\n",
       "  'tool_call_id': 'call_QCchvKp6V6q3biMbngK0D2b9'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The final result after adding \\\\(11\\\\) to \\\\(8\\\\) is \\\\(19\\\\). \\n\\nI will now terminate the process as there are no further actions to take.',\n",
       "  'tool_calls': None},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_PeWwaI7uRFy8UBJpEuS3MQvh', function=Function(arguments='{}', name='termination'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': 'StopReactLoopException',\n",
       "  'tool_call_id': 'call_PeWwaI7uRFy8UBJpEuS3MQvh'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The calculation is complete. If you have any more questions or need further assistance, feel free to ask!',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5a167",
   "metadata": {},
   "source": [
    "Key Steps in this Agent Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4798df",
   "metadata": {},
   "source": [
    "1) Environment and Base Classes\n",
    "\n",
    "    - Required libraries are imported, environment variables are loaded, and the OpenAI client is instantiated\n",
    "    - Helper classes are prepared\n",
    "        - Memory class for tracking conversation history\n",
    "        - Tool class abstraction for wrapping python functions with a JSON schema for tool calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebacc3",
   "metadata": {},
   "source": [
    "2) Controlling the ReAct Loop:\n",
    "\n",
    "    - A custom exception \"StopReactLoopException\" is defined to gracefully exit the reasoning loop when a task is complete\n",
    "    - A special \"termination\" function and correspong message are created so the LLM can explicitly choose to stop\n",
    "\n",
    "class StopReactLoopException(Exception):\n",
    "  pass\n",
    "\n",
    "def call_termination():\n",
    "  raise StopReactLoopException(\"Terminating the ReAct loop.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa13e6c4",
   "metadata": {},
   "source": [
    "3) Agent Class Design:\n",
    "\n",
    "    - The agent class manages the reasoning and tool execution steps\n",
    "\n",
    "    - Constructor Parameters:\n",
    "        - name\n",
    "        - role\n",
    "        - instructions\n",
    "        - model\n",
    "        - temperature\n",
    "        - tools\n",
    "    - Core components initialized\n",
    "        - Memory\n",
    "        - Tool Map and OpenAI tools\n",
    "        - Termination Handling\n",
    "        - system message guiding the thought-action structure\n",
    "\n",
    "\n",
    "class Agent:\n",
    "  def __init__(\n",
    "                self, \n",
    "                name=\"agent\", \n",
    "                role=\"personal assistant\", \n",
    "                instructions=..., \n",
    "                model=..., \n",
    "                temperature=0.7, \n",
    "                tools=[]):\n",
    "      ...\n",
    "\n",
    "\n",
    "    - Key Methods\n",
    "\n",
    "        - invoke(): This is the entry point for users questions, starting the planning loop.\n",
    "        - react_loop(): This is the main loop that alternates reasoning (plan generation) and action (tool use)\n",
    "        - reason(): creates a thought and selects an action without tools initially.\n",
    "        - call_tools(): executes a tool when the model specifies a tool call\n",
    "        - get_completion(): wraps a standard call to the Openai chat model.\n",
    "        - register_tool(): adds user-defined tools into the agents toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eedf3f",
   "metadata": {},
   "source": [
    "4) Tool Creation\n",
    "\n",
    "    - Two tools are created\n",
    "        -power(base, exponent) - calculates exponentiation\n",
    "        -sum_numbers(num_1, num_2)\n",
    "\n",
    "    - These tools are wrapped with JSON schema metadata so the LLM understands their parameters\n",
    "\n",
    "\n",
    "def power(base: float, exponent: float) -> float:\n",
    "  return base ** exponent\n",
    "\n",
    "def sum_numbers(a: float, b: float) -> float:\n",
    "  return a + b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
